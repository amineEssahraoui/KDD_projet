{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82b81b5d",
   "metadata": {},
   "source": [
    "# LightGBM Scratch â€“ End-to-End Benchmarks\n",
    "\n",
    "This notebook consolidates the example scripts into one place:\n",
    "\n",
    "\n",
    "\n",
    "- California Housing regression (clean)\n",
    "\n",
    "- California Housing regression with NaNs and sparse noise features\n",
    "\n",
    "- Credit-risk binary classification with imbalance handling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "343e519b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.6 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 701, in start\n",
      "    self.io_loop.start()\n",
      "  File \"c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"c:\\Users\\hp\\anaconda3\\Lib\\asyncio\\windows_events.py\", line 322, in run_forever\n",
      "    super().run_forever()\n",
      "  File \"c:\\Users\\hp\\anaconda3\\Lib\\asyncio\\base_events.py\", line 641, in run_forever\n",
      "    self._run_once()\n",
      "  File \"c:\\Users\\hp\\anaconda3\\Lib\\asyncio\\base_events.py\", line 1986, in _run_once\n",
      "    handle._run()\n",
      "  File \"c:\\Users\\hp\\anaconda3\\Lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 523, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 429, in dispatch_shell\n",
      "    await result\n",
      "  File \"c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 767, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 429, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12380\\3251639824.py\", line 6, in <module>\n",
      "    import pandas as pd\n",
      "  File \"c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\pandas\\__init__.py\", line 26, in <module>\n",
      "    from pandas.compat import (\n",
      "  File \"c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\pandas\\compat\\__init__.py\", line 27, in <module>\n",
      "    from pandas.compat.pyarrow import (\n",
      "  File \"c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\pandas\\compat\\pyarrow.py\", line 8, in <module>\n",
      "    import pyarrow as pa\n",
      "  File \"c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\pyarrow\\__init__.py\", line 65, in <module>\n",
      "    import pyarrow.lib as _lib\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "\nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.2.6 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\hp\\anaconda3\\Lib\\site-packages\\numpy\\core\\_multiarray_umath.py:44\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(attr_name)\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;66;03m# Also print the message (with traceback).  This is because old versions\u001b[39;00m\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;66;03m# of NumPy unfortunately set up the import to replace (and hide) the\u001b[39;00m\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;66;03m# error.  The traceback shouldn't be needed, but e.g. pytest plugins\u001b[39;00m\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;66;03m# seem to swallow it and we should be failing anyway...\u001b[39;00m\n\u001b[0;32m     43\u001b[0m     sys\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mwrite(msg \u001b[38;5;241m+\u001b[39m tb_msg)\n\u001b[1;32m---> 44\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[0;32m     46\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(_multiarray_umath, attr_name, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mImportError\u001b[0m: \nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.2.6 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.6 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 701, in start\n",
      "    self.io_loop.start()\n",
      "  File \"c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"c:\\Users\\hp\\anaconda3\\Lib\\asyncio\\windows_events.py\", line 322, in run_forever\n",
      "    super().run_forever()\n",
      "  File \"c:\\Users\\hp\\anaconda3\\Lib\\asyncio\\base_events.py\", line 641, in run_forever\n",
      "    self._run_once()\n",
      "  File \"c:\\Users\\hp\\anaconda3\\Lib\\asyncio\\base_events.py\", line 1986, in _run_once\n",
      "    handle._run()\n",
      "  File \"c:\\Users\\hp\\anaconda3\\Lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 523, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 429, in dispatch_shell\n",
      "    await result\n",
      "  File \"c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 767, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 429, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12380\\3251639824.py\", line 6, in <module>\n",
      "    import pandas as pd\n",
      "  File \"c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\pandas\\__init__.py\", line 49, in <module>\n",
      "    from pandas.core.api import (\n",
      "  File \"c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\pandas\\core\\api.py\", line 1, in <module>\n",
      "    from pandas._libs import (\n",
      "  File \"c:\\Users\\hp\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\__init__.py\", line 17, in <module>\n",
      "    import pandas._libs.pandas_datetime  # noqa: F401 # isort: skip # type: ignore[reportUnusedImport]\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "\nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.2.6 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\hp\\anaconda3\\Lib\\site-packages\\numpy\\core\\_multiarray_umath.py:44\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(attr_name)\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;66;03m# Also print the message (with traceback).  This is because old versions\u001b[39;00m\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;66;03m# of NumPy unfortunately set up the import to replace (and hide) the\u001b[39;00m\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;66;03m# error.  The traceback shouldn't be needed, but e.g. pytest plugins\u001b[39;00m\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;66;03m# seem to swallow it and we should be failing anyway...\u001b[39;00m\n\u001b[0;32m     43\u001b[0m     sys\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mwrite(msg \u001b[38;5;241m+\u001b[39m tb_msg)\n\u001b[1;32m---> 44\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[0;32m     46\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(_multiarray_umath, attr_name, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mImportError\u001b[0m: \nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.2.6 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "numpy.core.multiarray failed to import",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpathlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      9\u001b[0m     r2_score, root_mean_squared_error, mean_absolute_error, mean_pinball_loss,\n\u001b[0;32m     10\u001b[0m     accuracy_score, f1_score, roc_auc_score, log_loss,\n\u001b[0;32m     11\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\hp\\anaconda3\\Lib\\site-packages\\pandas\\__init__.py:49\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# let init-time option registration happen\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig_init\u001b[39;00m  \u001b[38;5;66;03m# pyright: ignore[reportUnusedImport] # noqa: F401\u001b[39;00m\n\u001b[1;32m---> 49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;66;03m# dtype\u001b[39;00m\n\u001b[0;32m     51\u001b[0m     ArrowDtype,\n\u001b[0;32m     52\u001b[0m     Int8Dtype,\n\u001b[0;32m     53\u001b[0m     Int16Dtype,\n\u001b[0;32m     54\u001b[0m     Int32Dtype,\n\u001b[0;32m     55\u001b[0m     Int64Dtype,\n\u001b[0;32m     56\u001b[0m     UInt8Dtype,\n\u001b[0;32m     57\u001b[0m     UInt16Dtype,\n\u001b[0;32m     58\u001b[0m     UInt32Dtype,\n\u001b[0;32m     59\u001b[0m     UInt64Dtype,\n\u001b[0;32m     60\u001b[0m     Float32Dtype,\n\u001b[0;32m     61\u001b[0m     Float64Dtype,\n\u001b[0;32m     62\u001b[0m     CategoricalDtype,\n\u001b[0;32m     63\u001b[0m     PeriodDtype,\n\u001b[0;32m     64\u001b[0m     IntervalDtype,\n\u001b[0;32m     65\u001b[0m     DatetimeTZDtype,\n\u001b[0;32m     66\u001b[0m     StringDtype,\n\u001b[0;32m     67\u001b[0m     BooleanDtype,\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# missing\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     NA,\n\u001b[0;32m     70\u001b[0m     isna,\n\u001b[0;32m     71\u001b[0m     isnull,\n\u001b[0;32m     72\u001b[0m     notna,\n\u001b[0;32m     73\u001b[0m     notnull,\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;66;03m# indexes\u001b[39;00m\n\u001b[0;32m     75\u001b[0m     Index,\n\u001b[0;32m     76\u001b[0m     CategoricalIndex,\n\u001b[0;32m     77\u001b[0m     RangeIndex,\n\u001b[0;32m     78\u001b[0m     MultiIndex,\n\u001b[0;32m     79\u001b[0m     IntervalIndex,\n\u001b[0;32m     80\u001b[0m     TimedeltaIndex,\n\u001b[0;32m     81\u001b[0m     DatetimeIndex,\n\u001b[0;32m     82\u001b[0m     PeriodIndex,\n\u001b[0;32m     83\u001b[0m     IndexSlice,\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;66;03m# tseries\u001b[39;00m\n\u001b[0;32m     85\u001b[0m     NaT,\n\u001b[0;32m     86\u001b[0m     Period,\n\u001b[0;32m     87\u001b[0m     period_range,\n\u001b[0;32m     88\u001b[0m     Timedelta,\n\u001b[0;32m     89\u001b[0m     timedelta_range,\n\u001b[0;32m     90\u001b[0m     Timestamp,\n\u001b[0;32m     91\u001b[0m     date_range,\n\u001b[0;32m     92\u001b[0m     bdate_range,\n\u001b[0;32m     93\u001b[0m     Interval,\n\u001b[0;32m     94\u001b[0m     interval_range,\n\u001b[0;32m     95\u001b[0m     DateOffset,\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;66;03m# conversion\u001b[39;00m\n\u001b[0;32m     97\u001b[0m     to_numeric,\n\u001b[0;32m     98\u001b[0m     to_datetime,\n\u001b[0;32m     99\u001b[0m     to_timedelta,\n\u001b[0;32m    100\u001b[0m     \u001b[38;5;66;03m# misc\u001b[39;00m\n\u001b[0;32m    101\u001b[0m     Flags,\n\u001b[0;32m    102\u001b[0m     Grouper,\n\u001b[0;32m    103\u001b[0m     factorize,\n\u001b[0;32m    104\u001b[0m     unique,\n\u001b[0;32m    105\u001b[0m     value_counts,\n\u001b[0;32m    106\u001b[0m     NamedAgg,\n\u001b[0;32m    107\u001b[0m     array,\n\u001b[0;32m    108\u001b[0m     Categorical,\n\u001b[0;32m    109\u001b[0m     set_eng_float_format,\n\u001b[0;32m    110\u001b[0m     Series,\n\u001b[0;32m    111\u001b[0m     DataFrame,\n\u001b[0;32m    112\u001b[0m )\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SparseDtype\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtseries\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m infer_freq\n",
      "File \u001b[1;32mc:\\Users\\hp\\anaconda3\\Lib\\site-packages\\pandas\\core\\api.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      2\u001b[0m     NaT,\n\u001b[0;32m      3\u001b[0m     Period,\n\u001b[0;32m      4\u001b[0m     Timedelta,\n\u001b[0;32m      5\u001b[0m     Timestamp,\n\u001b[0;32m      6\u001b[0m )\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmissing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NA\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     10\u001b[0m     ArrowDtype,\n\u001b[0;32m     11\u001b[0m     CategoricalDtype,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m     PeriodDtype,\n\u001b[0;32m     15\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\hp\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\__init__.py:17\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Below imports needs to happen first to ensure pandas top level\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# module gets monkeypatched with the pandas_datetime_CAPI\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# see pandas_datetime_exec in pd_datetime.c\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpandas_parser\u001b[39;00m  \u001b[38;5;66;03m# isort: skip # type: ignore[reportUnusedImport]\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpandas_datetime\u001b[39;00m  \u001b[38;5;66;03m# noqa: F401 # isort: skip # type: ignore[reportUnusedImport]\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minterval\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Interval\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtslibs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     20\u001b[0m     NaT,\n\u001b[0;32m     21\u001b[0m     NaTType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     26\u001b[0m     iNaT,\n\u001b[0;32m     27\u001b[0m )\n",
      "\u001b[1;31mImportError\u001b[0m: numpy.core.multiarray failed to import"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import sys, time\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    r2_score, root_mean_squared_error, mean_absolute_error, mean_pinball_loss,\n",
    "    accuracy_score, f1_score, roc_auc_score, log_loss,\n",
    "    )\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import GradientBoostingRegressor, GradientBoostingClassifier\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "\n",
    "def get_project_root() -> Path:\n",
    "    here = Path.cwd().resolve()\n",
    "    for cand in [here, *here.parents]:\n",
    "        if (cand / \"pyproject.toml\").exists() or (cand / \"src\").exists():\n",
    "            return cand\n",
    "    return here\n",
    "\n",
    "PROJECT_ROOT = get_project_root()\n",
    "SRC_ROOT = PROJECT_ROOT / \"src\"\n",
    "sys.path.insert(0, str(SRC_ROOT))\n",
    "sys.path.insert(1, str(PROJECT_ROOT))\n",
    "from lightgbm.lgbm_regressor import LGBMRegressor  # type: ignore\n",
    "from lightgbm.lgbm_classifier import LGBMClassifier  # type: ignore\n",
    "from lightgbm.loss_functions import HuberLoss, QuantileLoss\n",
    "\n",
    "\n",
    "def num_trees(model_name, model):\n",
    "    if \"GradientBoost\" in model_name:\n",
    "        return len(getattr(model, \"estimators_\", []))\n",
    "    if \"XGBoost\" in model_name:\n",
    "        bst = model.get_booster()\n",
    "        return len(bst.get_dump()) if bst is not None else getattr(model, \"n_estimators\", 0)\n",
    "    return len(getattr(model, \"trees_\", []))\n",
    "\n",
    "\n",
    "def eval_reg(model_name, model, X_train, X_test, y_train, y_test):\n",
    "    start = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    t = time.time() - start\n",
    "    y_pred = model.predict(X_test)\n",
    "    return {\n",
    "        \"Model\": model_name,\n",
    "        \"R2\": r2_score(y_test, y_pred),\n",
    "        \"RMSE\": root_mean_squared_error(y_test, y_pred),\n",
    "        \"MAE\": mean_absolute_error(y_test, y_pred),\n",
    "        \"Training time\": t,\n",
    "        \"Num Trees Used\": num_trees(model_name, model),\n",
    "        \"y_pred\": y_pred,\n",
    "    }\n",
    "\n",
    "\n",
    "def eval_clf(model_name, model, X_train, X_test, y_train, y_test, sample_weight=None):\n",
    "    start = time.time()\n",
    "    if sample_weight is not None:\n",
    "        try:\n",
    "            model.fit(X_train, y_train, sample_weight=sample_weight)\n",
    "        except TypeError:\n",
    "            model.fit(X_train, y_train)\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "    t = time.time() - start\n",
    "    y_pred = model.predict(X_test)\n",
    "    try:\n",
    "        y_proba = model.predict_proba(X_test)[:, 1]\n",
    "    except Exception:\n",
    "        y_proba = None\n",
    "    return {\n",
    "        \"Model\": model_name,\n",
    "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
    "        \"F1\": f1_score(y_test, y_pred),\n",
    "        \"AUC\": roc_auc_score(y_test, y_proba if y_proba is not None else y_pred),\n",
    "        \"LogLoss\": log_loss(y_test, y_proba if y_proba is not None else y_pred),\n",
    "        \"Training time\": t,\n",
    "        \"Num Trees Used\": num_trees(model_name, model),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76417f1",
   "metadata": {},
   "source": [
    "## 1) California Housing Regression (clean)\n",
    "\n",
    "Baseline regression comparison on the original dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d17a9c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoost                R2=0.8004  RMSE=0.5114  MAE=0.3483  t=6.5003  N=200\n",
      "XGBoost Regressor            R2=0.8301  RMSE=0.4718  MAE=0.3096  t=0.1239  N=100\n",
      "LightGBM-leaf_wise_mse       R2=0.8356  RMSE=0.4641  MAE=0.3088  t=28.4178  N=200\n",
      "LightGBM-histogram_efb_goss  R2=0.8363  RMSE=0.4632  MAE=0.3116  t=17.5686  N=150\n",
      "LightGBM-huber_robust        R2=0.8350  RMSE=0.4650  MAE=0.3065  t=30.9003  N=200\n",
      "LightGBM-regularized_shallow R2=0.8135  RMSE=0.4943  MAE=0.3353  t=36.8477  N=400\n",
      "LightGBM-fast_wide           R2=0.8282  RMSE=0.4745  MAE=0.3210  t=20.7249  N=120\n",
      "LightGBM-goss_parallel       R2=0.8435  RMSE=0.4528  MAE=0.3043  t=43.1367  N=250\n",
      "LightGBM-efb_parallel        R2=0.8369  RMSE=0.4623  MAE=0.3061  t=28.7785  N=180\n",
      "LightGBM-exact_small         R2=0.8051  RMSE=0.5053  MAE=0.3404  t=12.6179  N=120\n",
      "LightGBM-quantile_p50        pinball=0.1521  coverage=0.5094  t=37.8705  N=300\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>R2</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>Training time</th>\n",
       "      <th>Num Trees Used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LightGBM-goss_parallel</td>\n",
       "      <td>0.843513</td>\n",
       "      <td>0.452838</td>\n",
       "      <td>0.304336</td>\n",
       "      <td>43.136731</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LightGBM-efb_parallel</td>\n",
       "      <td>0.836878</td>\n",
       "      <td>0.462338</td>\n",
       "      <td>0.306090</td>\n",
       "      <td>28.778517</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LightGBM-histogram_efb_goss</td>\n",
       "      <td>0.836267</td>\n",
       "      <td>0.463204</td>\n",
       "      <td>0.311637</td>\n",
       "      <td>17.568600</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LightGBM-leaf_wise_mse</td>\n",
       "      <td>0.835621</td>\n",
       "      <td>0.464116</td>\n",
       "      <td>0.308764</td>\n",
       "      <td>28.417764</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LightGBM-huber_robust</td>\n",
       "      <td>0.835003</td>\n",
       "      <td>0.464987</td>\n",
       "      <td>0.306470</td>\n",
       "      <td>30.900329</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBoost Regressor</td>\n",
       "      <td>0.830137</td>\n",
       "      <td>0.471794</td>\n",
       "      <td>0.309573</td>\n",
       "      <td>0.123906</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LightGBM-fast_wide</td>\n",
       "      <td>0.828163</td>\n",
       "      <td>0.474528</td>\n",
       "      <td>0.321001</td>\n",
       "      <td>20.724862</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LightGBM-regularized_shallow</td>\n",
       "      <td>0.813543</td>\n",
       "      <td>0.494303</td>\n",
       "      <td>0.335272</td>\n",
       "      <td>36.847681</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LightGBM-exact_small</td>\n",
       "      <td>0.805142</td>\n",
       "      <td>0.505316</td>\n",
       "      <td>0.340412</td>\n",
       "      <td>12.617880</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GradientBoost</td>\n",
       "      <td>0.800445</td>\n",
       "      <td>0.511369</td>\n",
       "      <td>0.348343</td>\n",
       "      <td>6.500265</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Model        R2      RMSE       MAE  Training time  \\\n",
       "7        LightGBM-goss_parallel  0.843513  0.452838  0.304336      43.136731   \n",
       "8         LightGBM-efb_parallel  0.836878  0.462338  0.306090      28.778517   \n",
       "3   LightGBM-histogram_efb_goss  0.836267  0.463204  0.311637      17.568600   \n",
       "2        LightGBM-leaf_wise_mse  0.835621  0.464116  0.308764      28.417764   \n",
       "4         LightGBM-huber_robust  0.835003  0.464987  0.306470      30.900329   \n",
       "1             XGBoost Regressor  0.830137  0.471794  0.309573       0.123906   \n",
       "6            LightGBM-fast_wide  0.828163  0.474528  0.321001      20.724862   \n",
       "5  LightGBM-regularized_shallow  0.813543  0.494303  0.335272      36.847681   \n",
       "9          LightGBM-exact_small  0.805142  0.505316  0.340412      12.617880   \n",
       "0                 GradientBoost  0.800445  0.511369  0.348343       6.500265   \n",
       "\n",
       "   Num Trees Used  \n",
       "7             250  \n",
       "8             180  \n",
       "3             150  \n",
       "2             200  \n",
       "4             200  \n",
       "1             100  \n",
       "6             120  \n",
       "5             400  \n",
       "9             120  \n",
       "0             200  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = fetch_california_housing(as_frame=True, return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "regressors = [\n",
    "    (\"GradientBoost\", GradientBoostingRegressor(n_estimators=200, random_state=42)),\n",
    "    (\"XGBoost Regressor\", XGBRegressor()),\n",
    "    (\"LightGBM-leaf_wise_mse\", LGBMRegressor(\n",
    "        objective=\"mse\", learning_rate=0.1, num_iterations=200,\n",
    "        max_depth=6, num_leaves=31, min_data_in_leaf=20,\n",
    "        lambda_l2=0.0, lambda_l1=0.0,\n",
    "        bagging_fraction=0.8, feature_fraction=0.8,\n",
    "        use_histogram=True, max_bins=64, use_efb=False, enable_goss=False,\n",
    "    )),\n",
    "    (\"LightGBM-histogram_efb_goss\", LGBMRegressor(\n",
    "        objective=\"mse\", learning_rate=0.15, num_iterations=150,\n",
    "        max_depth=6, num_leaves=31, min_data_in_leaf=20,\n",
    "        lambda_l2=0.1, lambda_l1=0.0,\n",
    "        bagging_fraction=0.8, feature_fraction=0.8,\n",
    "        use_histogram=True, max_bins=64, use_efb=True, enable_goss=True,\n",
    "        goss_top_rate=0.2, goss_other_rate=0.1,\n",
    "    )),\n",
    "    (\"LightGBM-huber_robust\", LGBMRegressor(\n",
    "        objective=HuberLoss(delta=1.0), learning_rate=0.1, num_iterations=200,\n",
    "        max_depth=6, num_leaves=31, min_data_in_leaf=20,\n",
    "        lambda_l2=0.1, lambda_l1=0.05,\n",
    "        bagging_fraction=0.9, feature_fraction=0.9,\n",
    "        use_histogram=True, max_bins=64, use_efb=False, enable_goss=False,\n",
    "    )),\n",
    "    (\"LightGBM-regularized_shallow\", LGBMRegressor(\n",
    "        objective=\"mse\", learning_rate=0.05, num_iterations=400,\n",
    "        max_depth=4, num_leaves=15, min_data_in_leaf=30,\n",
    "        lambda_l2=1.0, lambda_l1=0.1,\n",
    "        bagging_fraction=0.7, feature_fraction=0.7,\n",
    "        use_histogram=True, max_bins=32, use_efb=False, enable_goss=False,\n",
    "    )),\n",
    "    (\"LightGBM-fast_wide\", LGBMRegressor(\n",
    "        objective=\"mse\", learning_rate=0.15, num_iterations=120,\n",
    "        max_depth=8, num_leaves=63, min_data_in_leaf=10,\n",
    "        lambda_l2=0.0, lambda_l1=0.0,\n",
    "        bagging_fraction=0.9, feature_fraction=0.9,\n",
    "        use_histogram=True, max_bins=32, use_efb=False, enable_goss=True,\n",
    "        goss_top_rate=0.2, goss_other_rate=0.1,\n",
    "    )),\n",
    "    (\"LightGBM-goss_parallel\", LGBMRegressor(\n",
    "        objective=\"mse\", learning_rate=0.08, num_iterations=250,\n",
    "        max_depth=7, num_leaves=63, min_data_in_leaf=15,\n",
    "        lambda_l2=0.2, lambda_l1=0.05,\n",
    "        bagging_fraction=0.9, feature_fraction=0.9,\n",
    "        use_histogram=True, max_bins=64, use_efb=False, enable_goss=True,\n",
    "        goss_top_rate=0.15, goss_other_rate=0.1,\n",
    "    )),\n",
    "    (\"LightGBM-efb_parallel\", LGBMRegressor(\n",
    "        objective=\"mse\", learning_rate=0.1, num_iterations=180,\n",
    "        max_depth=6, num_leaves=40, min_data_in_leaf=20,\n",
    "        lambda_l2=0.1, lambda_l1=0.0,\n",
    "        bagging_fraction=0.8, feature_fraction=0.9,\n",
    "        use_histogram=True, max_bins=64, use_efb=True, enable_goss=False,\n",
    "    )),\n",
    "    (\"LightGBM-exact_small\", LGBMRegressor(\n",
    "        objective=\"mse\", learning_rate=0.05, num_iterations=120,\n",
    "        max_depth=5, num_leaves=31, min_data_in_leaf=25,\n",
    "        lambda_l2=0.1, lambda_l1=0.05,\n",
    "        bagging_fraction=0.8, feature_fraction=0.8,\n",
    "        use_histogram=False, use_efb=False, enable_goss=False,\n",
    "    )),\n",
    "    (\"LightGBM-quantile_p50\", LGBMRegressor(\n",
    "        objective=QuantileLoss(quantile=0.5), learning_rate=0.08, num_iterations=300,\n",
    "        max_depth=5, num_leaves=25, min_data_in_leaf=20,\n",
    "        lambda_l2=0.2, lambda_l1=0.05,\n",
    "        bagging_fraction=0.8, feature_fraction=0.8,\n",
    "        use_histogram=True, max_bins=64, use_efb=False, enable_goss=False,\n",
    "    )),\n",
    "]\n",
    "\n",
    "reg_results = []\n",
    "for name, model in regressors:\n",
    "    res = eval_reg(name, model, X_train, X_test, y_train, y_test)\n",
    "    if name == \"LightGBM-quantile_p50\":\n",
    "        pb = mean_pinball_loss(y_test, res[\"y_pred\"], alpha=0.5)\n",
    "        cvg = np.mean(y_test <= res[\"y_pred\"])\n",
    "        print(f\"{name:<28} pinball={pb:.4f}  coverage={cvg:.4f}  t={res['Training time']:.4f}  N={res['Num Trees Used']}\")\n",
    "    else:\n",
    "        print(f\"{name:<28} R2={res['R2']:.4f}  RMSE={res['RMSE']:.4f}  MAE={res['MAE']:.4f}  t={res['Training time']:.4f}  N={res['Num Trees Used']}\")\n",
    "        reg_results.append({k: v for k, v in res.items() if k != \"y_pred\"})\n",
    "\n",
    "pd.DataFrame(reg_results).sort_values(by='R2', ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120f6405",
   "metadata": {},
   "source": [
    "## 2) Regression with NaNs and Sparse Noise\n",
    "\n",
    "Inject 30% NaNs and append 50 sparse noise features to stress EFB/GOSS and robustness.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e102cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Regressor            R2=0.6496  RMSE=0.6776  MAE=0.4817  t=0.5775  N=100\n",
      "LightGBM-leaf_wise_mse       R2=0.6424  RMSE=0.6846  MAE=0.4878  t=80.2770  N=200\n",
      "LightGBM-histogram_efb_goss  R2=0.6588  RMSE=0.6686  MAE=0.4730  t=17.6634  N=150\n",
      "LightGBM-huber_robust        R2=0.6435  RMSE=0.6835  MAE=0.4741  t=90.3031  N=200\n",
      "LightGBM-regularized_shallow R2=0.6098  RMSE=0.7151  MAE=0.5131  t=91.6388  N=400\n",
      "LightGBM-fast_wide           R2=0.6079  RMSE=0.7168  MAE=0.5138  t=57.7457  N=120\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 33\u001b[39m\n\u001b[32m     31\u001b[39m reg_results_noise = []\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m name, model \u001b[38;5;129;01min\u001b[39;00m regressors:\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m     res = \u001b[43meval_reg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train_aug\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test_aug\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     34\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m name == \u001b[33m\"\u001b[39m\u001b[33mLightGBM-quantile_p50\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m     35\u001b[39m         pb = mean_pinball_loss(y_test, res[\u001b[33m\"\u001b[39m\u001b[33my_pred\u001b[39m\u001b[33m\"\u001b[39m], alpha=\u001b[32m0.5\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 44\u001b[39m, in \u001b[36meval_reg\u001b[39m\u001b[34m(model_name, model, X_train, X_test, y_train, y_test)\u001b[39m\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34meval_reg\u001b[39m(model_name, model, X_train, X_test, y_train, y_test):\n\u001b[32m     43\u001b[39m     start = time.time()\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m     \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     45\u001b[39m     t = time.time() - start\n\u001b[32m     46\u001b[39m     y_pred = model.predict(X_test)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Bureau\\S7\\KDD\\KDD_projet\\src\\lightgbm\\lgbm_regressor.py:304\u001b[39m, in \u001b[36mLGBMRegressor.fit\u001b[39m\u001b[34m(self, X, y, eval_set, sample_weight, callbacks)\u001b[39m\n\u001b[32m    297\u001b[39m     \u001b[38;5;28mself\u001b[39m._goss = GOSS(\n\u001b[32m    298\u001b[39m         top_rate=\u001b[38;5;28mself\u001b[39m.params.goss_top_rate,\n\u001b[32m    299\u001b[39m         other_rate=\u001b[38;5;28mself\u001b[39m.params.goss_other_rate,\n\u001b[32m    300\u001b[39m         random_state=\u001b[38;5;28mself\u001b[39m.params.random_state,\n\u001b[32m    301\u001b[39m     )\n\u001b[32m    303\u001b[39m \u001b[38;5;66;03m# Training loop\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m304\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    306\u001b[39m \u001b[38;5;28mself\u001b[39m.is_fitted_ = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    307\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Bureau\\S7\\KDD\\KDD_projet\\src\\lightgbm\\lgbm_regressor.py:407\u001b[39m, in \u001b[36mLGBMRegressor._train\u001b[39m\u001b[34m(self, X, y, X_val, y_val, sample_weight)\u001b[39m\n\u001b[32m    392\u001b[39m \u001b[38;5;66;03m# Build tree\u001b[39;00m\n\u001b[32m    393\u001b[39m tree = DecisionTree(\n\u001b[32m    394\u001b[39m     max_depth=\u001b[38;5;28mself\u001b[39m.params.max_depth,\n\u001b[32m    395\u001b[39m     min_samples_leaf=\u001b[38;5;28mself\u001b[39m.params.min_data_in_leaf,\n\u001b[32m   (...)\u001b[39m\u001b[32m    404\u001b[39m     random_state=\u001b[38;5;28mself\u001b[39m.params.random_state,\n\u001b[32m    405\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m407\u001b[39m \u001b[43mtree\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradients_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhessians_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    409\u001b[39m \u001b[38;5;66;03m# Update predictions\u001b[39;00m\n\u001b[32m    410\u001b[39m tree_predictions = tree.predict(X)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Bureau\\S7\\KDD\\KDD_projet\\src\\lightgbm\\tree.py:246\u001b[39m, in \u001b[36mDecisionTree.fit\u001b[39m\u001b[34m(self, X, gradients, hessians, sample_weight)\u001b[39m\n\u001b[32m    243\u001b[39m indices = np.arange(n_samples)\n\u001b[32m    245\u001b[39m \u001b[38;5;66;03m# Build tree using leaf-wise growth\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m246\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_build_tree_leaf_wise\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradients\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhessians\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Bureau\\S7\\KDD\\KDD_projet\\src\\lightgbm\\tree.py:339\u001b[39m, in \u001b[36mDecisionTree._build_tree_leaf_wise\u001b[39m\u001b[34m(self, X, gradients, hessians, indices)\u001b[39m\n\u001b[32m    334\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m child, child_indices \u001b[38;5;129;01min\u001b[39;00m [\n\u001b[32m    335\u001b[39m     (node.left, left_indices),\n\u001b[32m    336\u001b[39m     (node.right, right_indices),\n\u001b[32m    337\u001b[39m ]:\n\u001b[32m    338\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(child_indices) >= \u001b[32m2\u001b[39m * \u001b[38;5;28mself\u001b[39m.min_samples_leaf:\n\u001b[32m--> \u001b[39m\u001b[32m339\u001b[39m         child_split = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_find_best_split\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    340\u001b[39m \u001b[43m            \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradients\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhessians\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchild_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchild\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdepth\u001b[49m\n\u001b[32m    341\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    342\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m child_split.gain > \u001b[38;5;28mself\u001b[39m.min_gain_to_split:\n\u001b[32m    343\u001b[39m             heapq.heappush(\n\u001b[32m    344\u001b[39m                 split_candidates,\n\u001b[32m    345\u001b[39m                 (-child_split.gain, node_counter, child, child_indices, child_split)\n\u001b[32m    346\u001b[39m             )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Bureau\\S7\\KDD\\KDD_projet\\src\\lightgbm\\tree.py:400\u001b[39m, in \u001b[36mDecisionTree._find_best_split\u001b[39m\u001b[34m(self, X, gradients, hessians, indices, depth)\u001b[39m\n\u001b[32m    397\u001b[39m feature_values = X[indices, feature_idx]\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.use_histogram:\n\u001b[32m--> \u001b[39m\u001b[32m400\u001b[39m     split_info = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_find_best_split_histogram\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfeature_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_gradients\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_hessians\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[43m        \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mG_total\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mH_total\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurrent_score\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    405\u001b[39m     split_info = \u001b[38;5;28mself\u001b[39m._find_best_split_exact(\n\u001b[32m    406\u001b[39m         feature_values, node_gradients, node_hessians,\n\u001b[32m    407\u001b[39m         indices, feature_idx, G_total, H_total, current_score\n\u001b[32m    408\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Bureau\\S7\\KDD\\KDD_projet\\src\\lightgbm\\tree.py:557\u001b[39m, in \u001b[36mDecisionTree._find_best_split_histogram\u001b[39m\u001b[34m(self, feature_values, gradients, hessians, indices, feature_idx, G_total, H_total, current_score)\u001b[39m\n\u001b[32m    554\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(valid_values) < \u001b[32m2\u001b[39m:\n\u001b[32m    555\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m best_split\n\u001b[32m--> \u001b[39m\u001b[32m557\u001b[39m bin_indices = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdigitize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalid_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbin_edges\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    558\u001b[39m bin_indices = np.clip(bin_indices, \u001b[32m0\u001b[39m, n_bins - \u001b[32m1\u001b[39m)\n\u001b[32m    560\u001b[39m \u001b[38;5;66;03m# Use numpy bincount for fast histogram on valid (non-NaN) entries\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mazbi\\anaconda3\\envs\\rl_env\\Lib\\site-packages\\numpy\\lib\\_function_base_impl.py:5827\u001b[39m, in \u001b[36mdigitize\u001b[39m\u001b[34m(x, bins, right)\u001b[39m\n\u001b[32m   5825\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(bins) - _nx.searchsorted(bins[::-\u001b[32m1\u001b[39m], x, side=side)\n\u001b[32m   5826\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m5827\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_nx\u001b[49m\u001b[43m.\u001b[49m\u001b[43msearchsorted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbins\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mside\u001b[49m\u001b[43m=\u001b[49m\u001b[43mside\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mazbi\\anaconda3\\envs\\rl_env\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py:1527\u001b[39m, in \u001b[36msearchsorted\u001b[39m\u001b[34m(a, v, side, sorter)\u001b[39m\n\u001b[32m   1447\u001b[39m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_searchsorted_dispatcher)\n\u001b[32m   1448\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msearchsorted\u001b[39m(a, v, side=\u001b[33m'\u001b[39m\u001b[33mleft\u001b[39m\u001b[33m'\u001b[39m, sorter=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m   1449\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1450\u001b[39m \u001b[33;03m    Find indices where elements should be inserted to maintain order.\u001b[39;00m\n\u001b[32m   1451\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   1525\u001b[39m \u001b[33;03m    30  # The element at index 2 of the sorted array is 30.\u001b[39;00m\n\u001b[32m   1526\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1527\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43msearchsorted\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mside\u001b[49m\u001b[43m=\u001b[49m\u001b[43mside\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msorter\u001b[49m\u001b[43m=\u001b[49m\u001b[43msorter\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mazbi\\anaconda3\\envs\\rl_env\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py:57\u001b[39m, in \u001b[36m_wrapfunc\u001b[39m\u001b[34m(obj, method, *args, **kwds)\u001b[39m\n\u001b[32m     54\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, *args, **kwds)\n\u001b[32m     56\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbound\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m     59\u001b[39m     \u001b[38;5;66;03m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[32m     60\u001b[39m     \u001b[38;5;66;03m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     64\u001b[39m     \u001b[38;5;66;03m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[32m     65\u001b[39m     \u001b[38;5;66;03m# exception has a traceback chain.\u001b[39;00m\n\u001b[32m     66\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, *args, **kwds)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# GradientBoosting can't work with NaN value, hence we only leave XGBoost and our Light GBM\n",
    "regressors = regressors[1:]\n",
    "\n",
    "def mask_nan(X, ratio=0.3, seed=42):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    Xc = X.copy()\n",
    "    mask = rng.random(Xc.shape) < ratio\n",
    "    Xc.values[mask] = np.nan\n",
    "    return Xc\n",
    "\n",
    "def sparse_noise(n_samples, n_features, zero_ratio=0.8, seed=42):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    Z = rng.standard_normal((n_samples, n_features))\n",
    "    Z[rng.random((n_samples, n_features)) < zero_ratio] = 0.0\n",
    "    return Z\n",
    "\n",
    "X, y = fetch_california_housing(as_frame=True, return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = mask_nan(X_train, ratio=0.3, seed=1)\n",
    "X_test  = mask_nan(X_test,  ratio=0.3, seed=2)\n",
    "\n",
    "n_noise = 50\n",
    "noise_train = sparse_noise(len(X_train), n_noise, zero_ratio=0.8, seed=3)\n",
    "noise_test  = sparse_noise(len(X_test),  n_noise, zero_ratio=0.8, seed=4)\n",
    "noise_cols = [f\"noise_{i}\" for i in range(n_noise)]\n",
    "\n",
    "X_train_aug = pd.concat([X_train, pd.DataFrame(noise_train, columns=noise_cols, index=X_train.index)], axis=1)\n",
    "X_test_aug  = pd.concat([X_test,  pd.DataFrame(noise_test,  columns=noise_cols, index=X_test.index)], axis=1)\n",
    "\n",
    "reg_results_noise = []\n",
    "for name, model in regressors:\n",
    "    res = eval_reg(name, model, X_train_aug, X_test_aug, y_train, y_test)\n",
    "    if name == \"LightGBM-quantile_p50\":\n",
    "        pb = mean_pinball_loss(y_test, res[\"y_pred\"], alpha=0.5)\n",
    "        cvg = np.mean(y_test <= res[\"y_pred\"])\n",
    "        print(f\"{name:<28} pinball={pb:.4f}  coverage={cvg:.4f}  t={res['Training time']:.4f}  N={res['Num Trees Used']}\")\n",
    "    else:\n",
    "        print(f\"{name:<28} R2={res['R2']:.4f}  RMSE={res['RMSE']:.4f}  MAE={res['MAE']:.4f}  t={res['Training time']:.4f}  N={res['Num Trees Used']}\")\n",
    "        reg_results_noise.append({k: v for k, v in res.items() if k != \"y_pred\"})\n",
    "\n",
    "pd.DataFrame(reg_results_noise).sort_values(by='R2', ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dbb067c",
   "metadata": {},
   "source": [
    "## 3) Credit-Risk Classification (imbalanced)\n",
    "\n",
    "Binary classification with stratified split and class weighting; compares XGBoost and several LightGBM configs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31513fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class balance train: pos=5686, neg=20378, pos_weight=3.584\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Cannot convert input of type DataFrame to numpy array: could not convert string to float: 'MORTGAGE'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Bureau\\S7\\KDD\\KDD_projet\\src\\lightgbm\\utils.py:66\u001b[39m, in \u001b[36mcheck_array\u001b[39m\u001b[34m(X, ensure_2d, allow_nan, dtype, copy)\u001b[39m\n\u001b[32m     65\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(X, \u001b[33m'\u001b[39m\u001b[33mvalues\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m66\u001b[39m     X_out = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mValueError\u001b[39m: could not convert string to float: 'MORTGAGE'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 62\u001b[39m, in \u001b[36meval_clf\u001b[39m\u001b[34m(model_name, model, X_train, X_test, y_train, y_test, sample_weight)\u001b[39m\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m62\u001b[39m     \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     63\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Bureau\\S7\\KDD\\KDD_projet\\src\\lightgbm\\lgbm_classifier.py:277\u001b[39m, in \u001b[36mLGBMClassifier.fit\u001b[39m\u001b[34m(self, X, y, eval_set, sample_weight, callbacks)\u001b[39m\n\u001b[32m    276\u001b[39m \u001b[38;5;66;03m# Validate inputs\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m277\u001b[39m X, y = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    278\u001b[39m sample_weight = check_sample_weight(sample_weight, \u001b[38;5;28mlen\u001b[39m(y))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Bureau\\S7\\KDD\\KDD_projet\\src\\lightgbm\\lgbm_classifier.py:221\u001b[39m, in \u001b[36mLGBMClassifier._validate_inputs\u001b[39m\u001b[34m(self, X, y)\u001b[39m\n\u001b[32m    220\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Validate and preprocess inputs.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m221\u001b[39m X, y = \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m.\u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    222\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m X, y\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Bureau\\S7\\KDD\\KDD_projet\\src\\lightgbm\\utils.py:136\u001b[39m, in \u001b[36mcheck_X_y\u001b[39m\u001b[34m(X, y, allow_nan, multi_output)\u001b[39m\n\u001b[32m    110\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    111\u001b[39m \u001b[33;03mValidate X and y arrays for supervised learning.\u001b[39;00m\n\u001b[32m    112\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    134\u001b[39m \u001b[33;03m    If X and y have incompatible shapes.\u001b[39;00m\n\u001b[32m    135\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m X = \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    137\u001b[39m y = check_array(y, ensure_2d=\u001b[38;5;28;01mFalse\u001b[39;00m, allow_nan=\u001b[38;5;28;01mFalse\u001b[39;00m, dtype=\u001b[38;5;28mfloat\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Bureau\\S7\\KDD\\KDD_projet\\src\\lightgbm\\utils.py:70\u001b[39m, in \u001b[36mcheck_array\u001b[39m\u001b[34m(X, ensure_2d, allow_nan, dtype, copy)\u001b[39m\n\u001b[32m     69\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m---> \u001b[39m\u001b[32m70\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m     71\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCannot convert input of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(X).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m to numpy array: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     72\u001b[39m         )\n\u001b[32m     74\u001b[39m \u001b[38;5;66;03m# Ensure correct dtype\u001b[39;00m\n",
      "\u001b[31mTypeError\u001b[39m: Cannot convert input of type DataFrame to numpy array: could not convert string to float: 'MORTGAGE'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Bureau\\S7\\KDD\\KDD_projet\\src\\lightgbm\\utils.py:66\u001b[39m, in \u001b[36mcheck_array\u001b[39m\u001b[34m(X, ensure_2d, allow_nan, dtype, copy)\u001b[39m\n\u001b[32m     65\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(X, \u001b[33m'\u001b[39m\u001b[33mvalues\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m66\u001b[39m     X_out = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mValueError\u001b[39m: could not convert string to float: 'MORTGAGE'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 65\u001b[39m\n\u001b[32m     63\u001b[39m clf_results = []\n\u001b[32m     64\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m name, model \u001b[38;5;129;01min\u001b[39;00m classifiers:\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m     res = \u001b[43meval_clf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     66\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m     67\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m<28\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m acc=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mres[\u001b[33m'\u001b[39m\u001b[33mAccuracy\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m  f1=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mres[\u001b[33m'\u001b[39m\u001b[33mF1\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m  auc=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mres[\u001b[33m'\u001b[39m\u001b[33mAUC\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m  logloss=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mres[\u001b[33m'\u001b[39m\u001b[33mLogLoss\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m  t=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mres[\u001b[33m'\u001b[39m\u001b[33mTraining time\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m  N=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mres[\u001b[33m'\u001b[39m\u001b[33mNum Trees Used\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     68\u001b[39m     )\n\u001b[32m     69\u001b[39m     clf_results.append(res)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 64\u001b[39m, in \u001b[36meval_clf\u001b[39m\u001b[34m(model_name, model, X_train, X_test, y_train, y_test, sample_weight)\u001b[39m\n\u001b[32m     62\u001b[39m         model.fit(X_train, y_train, sample_weight=sample_weight)\n\u001b[32m     63\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m         \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     66\u001b[39m     model.fit(X_train, y_train)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Bureau\\S7\\KDD\\KDD_projet\\src\\lightgbm\\lgbm_classifier.py:277\u001b[39m, in \u001b[36mLGBMClassifier.fit\u001b[39m\u001b[34m(self, X, y, eval_set, sample_weight, callbacks)\u001b[39m\n\u001b[32m    274\u001b[39m \u001b[38;5;28mself\u001b[39m._validate_params()\n\u001b[32m    276\u001b[39m \u001b[38;5;66;03m# Validate inputs\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m277\u001b[39m X, y = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    278\u001b[39m sample_weight = check_sample_weight(sample_weight, \u001b[38;5;28mlen\u001b[39m(y))\n\u001b[32m    280\u001b[39m \u001b[38;5;66;03m# Store callbacks\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Bureau\\S7\\KDD\\KDD_projet\\src\\lightgbm\\lgbm_classifier.py:221\u001b[39m, in \u001b[36mLGBMClassifier._validate_inputs\u001b[39m\u001b[34m(self, X, y)\u001b[39m\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_validate_inputs\u001b[39m(\n\u001b[32m    216\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    217\u001b[39m     X: np.ndarray,\n\u001b[32m    218\u001b[39m     y: np.ndarray,\n\u001b[32m    219\u001b[39m ) -> Tuple[np.ndarray, np.ndarray]:\n\u001b[32m    220\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Validate and preprocess inputs.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m221\u001b[39m     X, y = \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m.\u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    222\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m X, y\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Bureau\\S7\\KDD\\KDD_projet\\src\\lightgbm\\utils.py:136\u001b[39m, in \u001b[36mcheck_X_y\u001b[39m\u001b[34m(X, y, allow_nan, multi_output)\u001b[39m\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcheck_X_y\u001b[39m(\n\u001b[32m    104\u001b[39m     X: ArrayLike,\n\u001b[32m    105\u001b[39m     y: ArrayLike,\n\u001b[32m   (...)\u001b[39m\u001b[32m    108\u001b[39m     multi_output: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    109\u001b[39m ) -> Tuple[np.ndarray, np.ndarray]:\n\u001b[32m    110\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    111\u001b[39m \u001b[33;03m    Validate X and y arrays for supervised learning.\u001b[39;00m\n\u001b[32m    112\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    134\u001b[39m \u001b[33;03m        If X and y have incompatible shapes.\u001b[39;00m\n\u001b[32m    135\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m     X = \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    137\u001b[39m     y = check_array(y, ensure_2d=\u001b[38;5;28;01mFalse\u001b[39;00m, allow_nan=\u001b[38;5;28;01mFalse\u001b[39;00m, dtype=\u001b[38;5;28mfloat\u001b[39m)\n\u001b[32m    139\u001b[39m     \u001b[38;5;66;03m# Flatten y if needed\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Bureau\\S7\\KDD\\KDD_projet\\src\\lightgbm\\utils.py:70\u001b[39m, in \u001b[36mcheck_array\u001b[39m\u001b[34m(X, ensure_2d, allow_nan, dtype, copy)\u001b[39m\n\u001b[32m     68\u001b[39m             X_out = np.asarray(X, dtype=dtype)\n\u001b[32m     69\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m---> \u001b[39m\u001b[32m70\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m     71\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCannot convert input of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(X).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m to numpy array: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     72\u001b[39m         )\n\u001b[32m     74\u001b[39m \u001b[38;5;66;03m# Ensure correct dtype\u001b[39;00m\n\u001b[32m     75\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m X_out.dtype != dtype:\n",
      "\u001b[31mTypeError\u001b[39m: Cannot convert input of type DataFrame to numpy array: could not convert string to float: 'MORTGAGE'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(PROJECT_ROOT / \"examples\" / \"credit_risk_dataset.csv\")\n",
    "X = df.drop(columns=[\"person_income\", \"loan_status\"])\n",
    "y = df[\"loan_status\"].astype(int)\n",
    "\n",
    "cat_cols = ['person_home_ownership', 'loan_intent', 'loan_grade', 'cb_person_default_on_file']\n",
    "for col in cat_cols:\n",
    "    le = LabelEncoder()\n",
    "    X[col] = le.fit_transform(X[col].astype(str))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "pos = (y_train == 1).sum()\n",
    "neg = (y_train == 0).sum()\n",
    "pos_weight = neg / max(pos, 1)\n",
    "sample_weight = np.where(y_train == 1, pos_weight, 1.0)\n",
    "print(f\"Class balance train: pos={pos}, neg={neg}, pos_weight={pos_weight:.3f}\")\n",
    "\n",
    "classifiers = [\n",
    "    # (\"XGBoostClassifier\", XGBClassifier(\n",
    "    #    objective=\"binary:logistic\", eval_metric=\"logloss\",\n",
    "    #    random_state=42, scale_pos_weight=pos_weight,\n",
    "    #)),\n",
    "    (\"LightGBM-leaf_wise_binary\", LGBMClassifier(\n",
    "        objective=\"binary\", learning_rate=0.1, num_iterations=200,\n",
    "        max_depth=6, num_leaves=31, min_data_in_leaf=20,\n",
    "        lambda_l2=0.0, lambda_l1=0.0,\n",
    "        bagging_fraction=0.8, feature_fraction=0.8,\n",
    "        use_histogram=True, max_bins=64, use_efb=False, enable_goss=False,\n",
    "    )),\n",
    "    (\"LightGBM-histogram_efb_goss\", LGBMClassifier(\n",
    "        objective=\"binary\", learning_rate=0.12, num_iterations=160,\n",
    "        max_depth=6, num_leaves=31, min_data_in_leaf=20,\n",
    "        lambda_l2=0.1, lambda_l1=0.0,\n",
    "        bagging_fraction=0.8, feature_fraction=0.8,\n",
    "        use_histogram=True, max_bins=64, use_efb=True, enable_goss=True,\n",
    "        goss_top_rate=0.2, goss_other_rate=0.1,\n",
    "    )),\n",
    "    (\"LightGBM-regularized_shallow\", LGBMClassifier(\n",
    "        objective=\"binary\", learning_rate=0.05, num_iterations=300,\n",
    "        max_depth=4, num_leaves=15, min_data_in_leaf=30,\n",
    "        lambda_l2=0.5, lambda_l1=0.05,\n",
    "        bagging_fraction=0.7, feature_fraction=0.7,\n",
    "        use_histogram=True, max_bins=32, use_efb=False, enable_goss=False,\n",
    "    )),\n",
    "    (\"LightGBM-fast_wide\", LGBMClassifier(\n",
    "        objective=\"binary\", learning_rate=0.12, num_iterations=140,\n",
    "        max_depth=8, num_leaves=63, min_data_in_leaf=10,\n",
    "        lambda_l2=0.05, lambda_l1=0.0,\n",
    "        bagging_fraction=0.9, feature_fraction=0.9,\n",
    "        use_histogram=True, max_bins=32, use_efb=False, enable_goss=True,\n",
    "        goss_top_rate=0.2, goss_other_rate=0.1,\n",
    "    )),\n",
    "    (\"LightGBM-efb_parallel\", LGBMClassifier(\n",
    "        objective=\"binary\", learning_rate=0.1, num_iterations=200,\n",
    "        max_depth=6, num_leaves=40, min_data_in_leaf=20,\n",
    "        lambda_l2=0.1, lambda_l1=0.0,\n",
    "        bagging_fraction=0.8, feature_fraction=0.9,\n",
    "        use_histogram=True, max_bins=64, use_efb=True, enable_goss=False,\n",
    "    )),\n",
    "]\n",
    "\n",
    "clf_results = []\n",
    "for name, model in classifiers:\n",
    "    res = eval_clf(name, model, X_train, X_test, y_train, y_test, sample_weight)\n",
    "    print(\n",
    "        f\"{name:<28} acc={res['Accuracy']:.4f}  f1={res['F1']:.4f}  auc={res['AUC']:.4f}  logloss={res['LogLoss']:.4f}  t={res['Training time']:.4f}  N={res['Num Trees Used']}\"\n",
    "    )\n",
    "    clf_results.append(res)\n",
    "\n",
    "pd.DataFrame(clf_results).sort_values(by='Accuracy', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05822ec2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
